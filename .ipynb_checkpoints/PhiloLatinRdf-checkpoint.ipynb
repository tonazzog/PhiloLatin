{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "503c3b5a-a58c-4514-a5db-9c2a85d0644e",
   "metadata": {},
   "source": [
    "## Linking Latin Philosophical Expressions project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f50a9a-3b40-4432-8059-1e7f728a53c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11dff992-fb7e-4fff-bc4c-9d11acb60604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import pyconll\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b35eab-3459-4806-8dcb-465832ff5725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b56b52-04f6-418c-aca6-cb2be67e6e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_expression_id(expression):\n",
    "    expression = expression.lower().replace(\",\", \"\").replace(\"?\", \"\")\n",
    "    w = expression.split(\" \")\n",
    "    return \"_\".join(w[ : 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bc0bfa-0861-4f5c-83a2-5d6b7a48b63c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dd1d41f-aacd-4d7c-aad0-4a6fd94891df",
   "metadata": {},
   "source": [
    "### Latin philosophical expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41d5def0-dc90-4e05-b1c2-4024bd2a90ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_latin = pd.read_csv('./Latin-Philosophical-Expressions.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f14975e-1e25-4399-aab2-3befd5f97615",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_latin = df_latin.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73936644-f7bd-4873-bed6-e6410895a1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>latin_expression</th>\n",
       "      <th>expression_url</th>\n",
       "      <th>branch</th>\n",
       "      <th>branch_url</th>\n",
       "      <th>concept</th>\n",
       "      <th>translation_eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a_dicto_secundum_quid</td>\n",
       "      <td>a dicto secundum quid ad dictum simpliciter</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q2456273</td>\n",
       "      <td>logic</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q8078</td>\n",
       "      <td>The phrase 'a dicto secundum quid ad dictum si...</td>\n",
       "      <td>from a statement qualified to a statement unqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a_dicto_simpliciter_ad</td>\n",
       "      <td>a dicto simpliciter ad dictum secundum quid</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q4660909</td>\n",
       "      <td>logic</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q8078</td>\n",
       "      <td>The Latin phrase 'a dicto simpliciter ad dictu...</td>\n",
       "      <td>from the saying absolutely to the saying with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a_fortiori</td>\n",
       "      <td>a fortiori</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q1753631</td>\n",
       "      <td>logic</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q8078</td>\n",
       "      <td>The Latin phrase 'a fortiori' translates to 'f...</td>\n",
       "      <td>a fortiori</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a_necesse_ad_esse</td>\n",
       "      <td>a necesse ad esse valet consequentia</td>\n",
       "      <td></td>\n",
       "      <td>logic</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q8078</td>\n",
       "      <td>The Latin phrase 'a necesse ad esse valet cons...</td>\n",
       "      <td>From necessity to being, the consequence holds.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a_posteriori</td>\n",
       "      <td>a posteriori</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q300637</td>\n",
       "      <td>epistemology</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q9471</td>\n",
       "      <td>The term 'a posteriori' is a Latin phrase mean...</td>\n",
       "      <td>from the latter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                             latin_expression  \\\n",
       "0   a_dicto_secundum_quid  a dicto secundum quid ad dictum simpliciter   \n",
       "1  a_dicto_simpliciter_ad  a dicto simpliciter ad dictum secundum quid   \n",
       "2              a_fortiori                                   a fortiori   \n",
       "3       a_necesse_ad_esse         a necesse ad esse valet consequentia   \n",
       "4            a_posteriori                                 a posteriori   \n",
       "\n",
       "                           expression_url        branch  \\\n",
       "0  https://www.wikidata.org/wiki/Q2456273         logic   \n",
       "1  https://www.wikidata.org/wiki/Q4660909         logic   \n",
       "2  https://www.wikidata.org/wiki/Q1753631         logic   \n",
       "3                                                 logic   \n",
       "4   https://www.wikidata.org/wiki/Q300637  epistemology   \n",
       "\n",
       "                            branch_url  \\\n",
       "0  https://www.wikidata.org/wiki/Q8078   \n",
       "1  https://www.wikidata.org/wiki/Q8078   \n",
       "2  https://www.wikidata.org/wiki/Q8078   \n",
       "3  https://www.wikidata.org/wiki/Q8078   \n",
       "4  https://www.wikidata.org/wiki/Q9471   \n",
       "\n",
       "                                             concept  \\\n",
       "0  The phrase 'a dicto secundum quid ad dictum si...   \n",
       "1  The Latin phrase 'a dicto simpliciter ad dictu...   \n",
       "2  The Latin phrase 'a fortiori' translates to 'f...   \n",
       "3  The Latin phrase 'a necesse ad esse valet cons...   \n",
       "4  The term 'a posteriori' is a Latin phrase mean...   \n",
       "\n",
       "                                     translation_eng  \n",
       "0  from a statement qualified to a statement unqu...  \n",
       "1  from the saying absolutely to the saying with ...  \n",
       "2                                         a fortiori  \n",
       "3    From necessity to being, the consequence holds.  \n",
       "4                                    from the latter  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_latin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5d54e4c-6a65-4a39-abad-91230d317dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on small dataset\n",
    "#expressions_filtered = []\n",
    "#with open('./expressions_filtered.txt') as f:\n",
    "#    expressions_filtered = f.read().split(\"\\n\")\n",
    "#df_latin = df_latin[df_latin['latin_expression'].isin(expressions_filtered)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b31cbd-dbd9-439b-b12f-53be0e8c12a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f340b83-c7b2-49d3-be06-8d97b6f0a39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8305bbd-16d6-48f3-a1d2-7f7eaf5dc317",
   "metadata": {},
   "source": [
    "### Different interpretations (senses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6845be37-e863-420b-b8ea-039cbdf901df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senses = pd.read_csv('./Latin-Expressions-Interpretations.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "126c08b1-caa9-4327-8252-c5ba2aebb14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senses = df_senses.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0101e6fc-fcda-45c4-bfbb-2b33707303c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expression</th>\n",
       "      <th>associated_with</th>\n",
       "      <th>sense</th>\n",
       "      <th>id</th>\n",
       "      <th>associated_with_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a dicto secundum quid ad dictum simpliciter</td>\n",
       "      <td>Aristotle</td>\n",
       "      <td>Aristotle uses this expression to differentiat...</td>\n",
       "      <td>a_dicto_secundum_quid</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q84473023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a dicto secundum quid ad dictum simpliciter</td>\n",
       "      <td>Thomas Aquinas</td>\n",
       "      <td>Aquinas interprets this phrase in the context ...</td>\n",
       "      <td>a_dicto_secundum_quid</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q9438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a dicto secundum quid ad dictum simpliciter</td>\n",
       "      <td>Immanuel Kant</td>\n",
       "      <td>Kant might interpret this expression in relati...</td>\n",
       "      <td>a_dicto_secundum_quid</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q9312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a dicto secundum quid ad dictum simpliciter</td>\n",
       "      <td>Leibniz</td>\n",
       "      <td>Leibniz could view this distinction as a refle...</td>\n",
       "      <td>a_dicto_secundum_quid</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q9047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a dicto simpliciter ad dictum secundum quid</td>\n",
       "      <td>Aristotle</td>\n",
       "      <td>Aristotle uses this expression to differentiat...</td>\n",
       "      <td>a_dicto_simpliciter_ad</td>\n",
       "      <td>https://www.wikidata.org/wiki/Q84473023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    expression associated_with  \\\n",
       "0  a dicto secundum quid ad dictum simpliciter       Aristotle   \n",
       "1  a dicto secundum quid ad dictum simpliciter  Thomas Aquinas   \n",
       "2  a dicto secundum quid ad dictum simpliciter   Immanuel Kant   \n",
       "3  a dicto secundum quid ad dictum simpliciter         Leibniz   \n",
       "4  a dicto simpliciter ad dictum secundum quid       Aristotle   \n",
       "\n",
       "                                               sense                      id  \\\n",
       "0  Aristotle uses this expression to differentiat...   a_dicto_secundum_quid   \n",
       "1  Aquinas interprets this phrase in the context ...   a_dicto_secundum_quid   \n",
       "2  Kant might interpret this expression in relati...   a_dicto_secundum_quid   \n",
       "3  Leibniz could view this distinction as a refle...   a_dicto_secundum_quid   \n",
       "4  Aristotle uses this expression to differentiat...  a_dicto_simpliciter_ad   \n",
       "\n",
       "                       associated_with_url  \n",
       "0  https://www.wikidata.org/wiki/Q84473023  \n",
       "1      https://www.wikidata.org/wiki/Q9438  \n",
       "2      https://www.wikidata.org/wiki/Q9312  \n",
       "3      https://www.wikidata.org/wiki/Q9047  \n",
       "4  https://www.wikidata.org/wiki/Q84473023  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_senses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaa8e71-073f-457e-ac64-1ee1985ea936",
   "metadata": {},
   "source": [
    "## Linking to LiLa lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98817f0d-41b8-4cf0-a726-a86387265650",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./lila_linking_final.json\", \"r\") as f:\n",
    "    text = f.read()\n",
    "lila_linking = json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3d2c79-8d62-4511-a9ab-fe78b19fbbfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1609867d-55c6-40e6-a738-3f53c747be7c",
   "metadata": {},
   "source": [
    "## Linked concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "000a7dc0-e283-469c-9723-1f64af1824c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "linked_concepts = [\n",
    "    [\"a dicto secundum quid ad dictum simpliciter\",\"a dicto simpliciter ad dictum secundum quid\"],\n",
    "    [\"a priori\",\"a posteriori\",\"a fortiori\"],\n",
    "    [\"argumentum ad baculum\",\"argumentum ad hominem\",\"argumentum ad populum\"],\n",
    "    [\"bellum omnium contra omnes\",\"homo homini lupus\"],\n",
    "    [\"modus ponens\",\"modus tollens\"],\n",
    "    [\"de dicto\",\"de facto\",\"de jure\",\"de re\"],\n",
    "    [\"in actu\",\"in esse\",\"in potentia\"],\n",
    "    [\"mundus intelligibilis\",\"mundus sensibilis\"],\n",
    "    [\"per accidens\",\"per se\"],\n",
    "    [\"res cogitans\", \"res extensa\"],\n",
    "    [\"tabula rasa\",\"nihil in intellectu nisi prius in sensu\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05a8baf4-fd02-44d1-8ee5-817deae7a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "linked_concepts_list = [generate_expression_id(concept)  for concepts in linked_concepts for concept in concepts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "435a933a-153c-44a8-b91c-edc34cb5ab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "linked_concepts_dict = {c : {'uri':'', 'links' : []} for c in set(linked_concepts_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec1e8b28-c150-44c5-99c3-6e6643620293",
   "metadata": {},
   "outputs": [],
   "source": [
    "for concepts in linked_concepts:\n",
    "    for concept in concepts:\n",
    "        concept_id = generate_expression_id(concept)       \n",
    "        for linked_concept in concepts:\n",
    "            if linked_concept != concept:\n",
    "                 linked_concepts_dict[concept_id]['links'].append(generate_expression_id(linked_concept))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "321bf6cc-b5ea-46eb-adad-595a1841d290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_potentia': {'uri': '', 'links': ['in_actu', 'in_esse']},\n",
       " 'per_se': {'uri': '', 'links': ['per_accidens']},\n",
       " 'nihil_in_intellectu_nisi': {'uri': '', 'links': ['tabula_rasa']},\n",
       " 'de_facto': {'uri': '', 'links': ['de_dicto', 'de_jure', 'de_re']},\n",
       " 'tabula_rasa': {'uri': '', 'links': ['nihil_in_intellectu_nisi']},\n",
       " 'modus_ponens': {'uri': '', 'links': ['modus_tollens']},\n",
       " 'de_jure': {'uri': '', 'links': ['de_dicto', 'de_facto', 'de_re']},\n",
       " 'de_dicto': {'uri': '', 'links': ['de_facto', 'de_jure', 'de_re']},\n",
       " 'argumentum_ad_baculum': {'uri': '',\n",
       "  'links': ['argumentum_ad_hominem', 'argumentum_ad_populum']},\n",
       " 'a_fortiori': {'uri': '', 'links': ['a_priori', 'a_posteriori']},\n",
       " 'homo_homini_lupus': {'uri': '', 'links': ['bellum_omnium_contra_omnes']},\n",
       " 'argumentum_ad_populum': {'uri': '',\n",
       "  'links': ['argumentum_ad_baculum', 'argumentum_ad_hominem']},\n",
       " 'a_posteriori': {'uri': '', 'links': ['a_priori', 'a_fortiori']},\n",
       " 'bellum_omnium_contra_omnes': {'uri': '', 'links': ['homo_homini_lupus']},\n",
       " 'mundus_intelligibilis': {'uri': '', 'links': ['mundus_sensibilis']},\n",
       " 'a_dicto_simpliciter_ad': {'uri': '', 'links': ['a_dicto_secundum_quid']},\n",
       " 'res_cogitans': {'uri': '', 'links': ['res_extensa']},\n",
       " 'de_re': {'uri': '', 'links': ['de_dicto', 'de_facto', 'de_jure']},\n",
       " 'a_priori': {'uri': '', 'links': ['a_posteriori', 'a_fortiori']},\n",
       " 'per_accidens': {'uri': '', 'links': ['per_se']},\n",
       " 'a_dicto_secundum_quid': {'uri': '', 'links': ['a_dicto_simpliciter_ad']},\n",
       " 'mundus_sensibilis': {'uri': '', 'links': ['mundus_intelligibilis']},\n",
       " 'res_extensa': {'uri': '', 'links': ['res_cogitans']},\n",
       " 'modus_tollens': {'uri': '', 'links': ['modus_ponens']},\n",
       " 'in_actu': {'uri': '', 'links': ['in_esse', 'in_potentia']},\n",
       " 'argumentum_ad_hominem': {'uri': '',\n",
       "  'links': ['argumentum_ad_baculum', 'argumentum_ad_populum']},\n",
       " 'in_esse': {'uri': '', 'links': ['in_actu', 'in_potentia']}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linked_concepts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59666d8a-c330-40d8-ab83-39ada25c0fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "965324d8-5c7b-44a5-8c18-b8edd997fb28",
   "metadata": {},
   "source": [
    "## UDPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "28dbb851-621d-4b94-9f98-f7d326850bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 502: <html>\n",
      "<head><title>502 Bad Gateway</title></head>\n",
      "<body>\n",
      "<center><h1>502 Bad Gateway</h1></center>\n",
      "<hr><center>nginx/1.20.1</center>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def call_udpipe_and_parse(text, model='latin-evalatin24-240520'):\n",
    "    url = 'https://lindat.mff.cuni.cz/services/udpipe/api/process'\n",
    "    params = {\n",
    "        'tokenizer': '',\n",
    "        'tagger': '',\n",
    "        'parser': '',\n",
    "        'data': text,\n",
    "        'model': model\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, data=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        conllu_result = result.get('result')\n",
    "        if conllu_result:\n",
    "            # Parse CoNLL-U with pyconll\n",
    "            conll_data = pyconll.load_from_string(conllu_result)\n",
    "            return conll_data\n",
    "        else:\n",
    "            print(\"No CoNLL-U output found. Error:\", result.get('error', 'Unknown error'))\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"HTTP Error {response.status_code}: {response.text}\")\n",
    "        return None\n",
    "\n",
    "connl = call_udpipe_and_parse(\"homo homini lupus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7d82ea27-5403-4aed-b713-dda7a006e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative function when UDPipe doesn't respond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3f6f97dc-2c90-42fb-9d3c-b3efe66c5b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 17:56:33 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0716cf5ef6c4d13ba7e4b2cd8ef09bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 17:56:33 INFO: Downloaded file to C:\\Users\\giovannt\\stanza_resources\\resources.json\n",
      "2025-05-26 17:56:34 INFO: Loading these models for language: la (Latin):\n",
      "=============================\n",
      "| Processor | Package       |\n",
      "-----------------------------\n",
      "| tokenize  | ittb          |\n",
      "| pos       | ittb_nocharlm |\n",
      "| lemma     | ittb_nocharlm |\n",
      "| depparse  | ittb_nocharlm |\n",
      "=============================\n",
      "\n",
      "2025-05-26 17:56:34 INFO: Using device: cpu\n",
      "2025-05-26 17:56:34 INFO: Loading: tokenize\n",
      "2025-05-26 17:56:34 INFO: Loading: pos\n",
      "2025-05-26 17:56:34 INFO: Loading: lemma\n",
      "2025-05-26 17:56:34 INFO: Loading: depparse\n",
      "2025-05-26 17:56:35 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "nlp = stanza.Pipeline(lang='la', processors='tokenize,pos,lemma,depparse')\n",
    "\n",
    "def call_udpipe_and_parse(text, model=''):\n",
    "    doc = nlp(text)\n",
    "    conllu_lines = []\n",
    "    for i, sentence in enumerate(doc.sentences, 1):\n",
    "        conllu_lines.append(f\"# sent_id = {i}\")\n",
    "        conllu_lines.append(f\"# text = {sentence.text}\")\n",
    "        for word in sentence.words:\n",
    "            line = [\n",
    "                str(word.id),\n",
    "                word.text,\n",
    "                word.lemma or \"_\",\n",
    "                word.upos or \"_\",\n",
    "                word.xpos or \"_\",\n",
    "                \"_\" if not word.feats else word.feats,\n",
    "                str(word.head),\n",
    "                word.deprel or \"_\",\n",
    "                \"_\",\n",
    "                \"_\"\n",
    "            ]\n",
    "            conllu_lines.append(\"\\t\".join(line))\n",
    "        conllu_lines.append(\"\")  # sentence separator\n",
    "    \n",
    "    conllu_result = \"\\n\".join(conllu_lines)\n",
    "    conll_data = pyconll.load_from_string(conllu_result)\n",
    "    return conll_data\n",
    "\n",
    "connl = call_udpipe_and_parse(\"homo homini lupus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d4ab0d-d65e-431f-93ca-0e57df4c9873",
   "metadata": {},
   "source": [
    "## Create triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7303794-0276-4728-9acf-143cb7d87e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace_sep = '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be914720-f440-42ce-8d4a-9091b8ad5b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uri(namespace, resource_type, identifier, namespace_sep, language=None):\n",
    "    \n",
    "    invalid_chars_pattern = r\"[^\\w]\"  # allow alphanumerics    \n",
    "    identifier = re.sub(invalid_chars_pattern, \"-\", str(identifier).lower())  \n",
    "    \n",
    "    if language:\n",
    "        # Language-specific resources\n",
    "        return namespace[f\"{resource_type}{namespace_sep}{language}{namespace_sep}{identifier}\"]\n",
    "    else:\n",
    "        # Language-neutral resources\n",
    "        return namespace[f\"{resource_type}{namespace_sep}{identifier}\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ec80fb4-e2d4-462e-8832-adfc5181a4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef, Literal, Namespace\n",
    "from rdflib.namespace import RDF, RDFS, OWL, DC, FOAF, SKOS, DCTERMS\n",
    "\n",
    "# Define namespaces\n",
    "ONTOLEX = Namespace(\"http://www.w3.org/ns/lemon/ontolex#\")\n",
    "LEXINFO = Namespace(\"http://www.lexinfo.net/ontology/2.0/lexinfo#\")\n",
    "LIME = Namespace(\"http://www.w3.org/ns/lemon/lime#\")\n",
    "VARTRANS = Namespace(\"http://www.w3.org/ns/lemon/vartrans#\")\n",
    "PROV = Namespace(\"http://www.w3.org/ns/prov#\")\n",
    "WD = Namespace(\"http://www.wikidata.org/entity/\")\n",
    "DCT = Namespace(\"http://purl.org/dc/terms/\")\n",
    "OA = Namespace(\"http://www.w3.org/ns/oa#\")\n",
    "\n",
    "POWLA = Namespace(\"http://purl.org/powla/powla.owl#\")\n",
    "LILA = Namespace(\"http://lila-erc.eu/ontologies/lila/\")\n",
    "\n",
    "# My namespace\n",
    "LP = Namespace(\"http://latinphilosophy.org/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "77c09278-d055-4e2f-8e6f-64028d3acbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a dicto secundum quid ad dictum simpliciter\n",
      "a dicto simpliciter ad dictum secundum quid\n",
      "a fortiori\n",
      "a necesse ad esse valet consequentia\n",
      "a posteriori\n",
      "a priori\n",
      "ab esse ad posse valet consequentia\n",
      "ab ovo\n",
      "actus purus\n",
      "ad hoc\n",
      "ad hoc hypothesis\n",
      "ad infinitum\n",
      "amicus Plato sed magis amica veritas\n",
      "amor fati\n",
      "anima mundi\n",
      "argumentum ad baculum\n",
      "argumentum ad hominem\n",
      "argumentum ad populum\n",
      "ars gratia artis\n",
      "barbara\n",
      "bellum omnium contra omnes\n",
      "causa sine qua non\n",
      "causa sui\n",
      "ceteris paribus\n",
      "characteristica universalis\n",
      "cogito, ergo sum\n",
      "conditio sine qua non\n",
      "consequentia mirabilis\n",
      "creatio ex nihilo\n",
      "credo quia absurdum est\n",
      "credo quia impossibile est\n",
      "credo ut intelligam\n",
      "cui bono?\n",
      "de dicto\n",
      "de facto\n",
      "de gustibus non disputandum\n",
      "de jure\n",
      "de re\n",
      "deus sive natura\n",
      "dictum de omni et nullo\n",
      "do ut des\n",
      "dubito, ergo cogito, ergo sum\n",
      "dum spiro, spero\n",
      "ens causa sui\n",
      "ens rationis\n",
      "ens realissimum\n",
      "entia non sunt multiplicanda praeter necessitatem\n",
      "esse est percipi\n",
      "ex falso quodlibet\n",
      "ex nihilo nihil fit\n",
      "ex post facto\n",
      "ex vi terminorum\n",
      "felix qui potuit rerum cognoscere causas\n",
      "fiat justitia ruat caelum\n",
      "fides quaerens intellectum\n",
      "fundamentum divisionis\n",
      "genius loci\n",
      "homo oeconomicus\n",
      "homo faber\n",
      "homo homini lupus\n",
      "hypotheses non fingo\n",
      "id quod nihil maius cogitari potest\n",
      "ignoratio elenchi\n",
      "in absentia\n",
      "in actu\n",
      "in cauda venenum\n",
      "in esse\n",
      "in medias res\n",
      "in nuce\n",
      "in potentia\n",
      "in propria persona\n",
      "intellectus agens\n",
      "intellectus possibilis\n",
      "inter finitum et infinitum non est proportio\n",
      "inventio medii\n",
      "ipse dixit\n",
      "ipsissima verba\n",
      "ipso facto\n",
      "lex parsimoniae\n",
      "lex talionis\n",
      "locus classicus\n",
      "materia prima\n",
      "memento mori\n",
      "mens rea\n",
      "modus ponens\n",
      "modus tollens\n",
      "modus vivendi\n",
      "mundus intelligibilis\n",
      "mundus sensibilis\n",
      "mutatis mutandis\n",
      "natura naturans\n",
      "natura naturata\n",
      "nihil in intellectu nisi prius in sensu\n",
      "nihil obstat\n",
      "nomen est omen\n",
      "non sequitur\n",
      "nosce te ipsum\n",
      "obiter dictum\n",
      "obscurum per obscurius\n",
      "per accidens\n",
      "per genus et differentiam\n",
      "per se\n",
      "per se notum\n",
      "persona non grata\n",
      "petitio principii\n",
      "phenomena bene fundata\n",
      "philosophia perennis\n",
      "pons asinorum\n",
      "post hoc ergo propter hoc\n",
      "prima causa\n",
      "prima facie\n",
      "primum mobile\n",
      "primum non nocere\n",
      "principium individuationis\n",
      "pro bono\n",
      "proprio motu\n",
      "quid pro quo\n",
      "quod erat demonstrandum\n",
      "quod gratis asseritur, gratis negatur\n",
      "quot homines tot sententiae\n",
      "ratio cognoscendi\n",
      "ratio essendi\n",
      "reductio ad absurdum\n",
      "res cogitans\n",
      "res extensa\n",
      "res publica\n",
      "sacrificium intellectus\n",
      "salva veritate\n",
      "scientia libera\n",
      "scientia media\n",
      "scientia naturalis\n",
      "sensus communis\n",
      "sensus divinitatis\n",
      "simplicius sigillum veri\n",
      "sine qua non\n",
      "solo numero\n",
      "solus ipse\n",
      "solvitur ambulando\n",
      "status quo\n",
      "stipendium peccati mors est\n",
      "sub specie aeternitatis\n",
      "sui generis\n",
      "summum bonum\n",
      "tabula rasa\n",
      "terminus ad quem\n",
      "tertium non datur\n",
      "tertium quid\n",
      "vade mecum\n",
      "veritas vos liberabit\n",
      "via negativa\n",
      "vice versa\n",
      "vis inertiae\n",
      "vox populi, vox dei\n"
     ]
    }
   ],
   "source": [
    "g = Graph()\n",
    "    \n",
    "# Binding\n",
    "g.bind(\"ontolex\", ONTOLEX)\n",
    "g.bind(\"lexinfo\", LEXINFO)\n",
    "g.bind(\"lime\", LIME)\n",
    "g.bind(\"skos\", SKOS)\n",
    "g.bind(\"dcterms\", DCTERMS)\n",
    "g.bind(\"vartrans\", VARTRANS)\n",
    "g.bind(\"prov\", PROV)\n",
    "g.bind(\"dct\", DCT)\n",
    "g.bind(\"powla\", POWLA)\n",
    "g.bind(\"foaf\", FOAF)\n",
    "g.bind(\"lila\", LILA)\n",
    "g.bind(\"oa\", OA)\n",
    "\n",
    "g.bind(\"lp\", LP)\n",
    "\n",
    "# Corpus\n",
    "corpus_uri =LP[\"corpus\"]\n",
    "g.add((corpus_uri, RDF.type, POWLA.Corpus))\n",
    "g.add((corpus_uri, RDFS.label, Literal('Philosophical Latin Expressions Corpus')))  \n",
    "g.add((corpus_uri, DCT.creator, Literal('Giovanna Tonazzo')))  \n",
    "\n",
    "# Document and expressions layers\n",
    "doc_uri = create_uri(LP,\"layer\", \"document\", namespace_sep)\n",
    "g.add((doc_uri, RDF.type, POWLA.DocumentLayer))\n",
    "g.add((doc_uri, RDFS.label, Literal('Document Layer')))\n",
    "g.add((doc_uri, POWLA.hasDocument, corpus_uri))\n",
    "\n",
    "cit_uri = create_uri(LP, \"layer\", \"expression\", namespace_sep)\n",
    "g.add((cit_uri, RDF.type, POWLA.DocumentLayer))\n",
    "g.add((cit_uri, RDFS.label, Literal('Expression Layer')))\n",
    "g.add((cit_uri, POWLA.hasDocument, corpus_uri))\n",
    "\n",
    "# Annotation layers\n",
    "ud_layer = create_uri(LP, \"layer\", \"ud\", namespace_sep)\n",
    "g.add((ud_layer, RDF.type, POWLA.Layer))\n",
    "g.add((ud_layer, RDFS.label, Literal('UD Annotation Layer')))  \n",
    "                                             \n",
    "sem_layer = create_uri(LP, \"layer\", \"semantics\", namespace_sep)\n",
    "g.add((sem_layer, RDF.type, POWLA.Layer))\n",
    "g.add((sem_layer, RDFS.label, Literal('Semantic Annotation Layer')))  \n",
    "         \n",
    "dep_layer = create_uri(LP, \"layer\", \"dependency\", namespace_sep)\n",
    "g.add((dep_layer, RDF.type, POWLA.Layer))\n",
    "g.add((dep_layer, RDFS.label, Literal('Dependency Annotation Layer')))\n",
    "\n",
    "g.add((corpus_uri, POWLA.hasLayer, ud_layer))\n",
    "g.add((corpus_uri, POWLA.hasLayer, sem_layer))\n",
    "g.add((corpus_uri, POWLA.hasLayer, dep_layer))\n",
    "\n",
    "# Lexicon for Latin and English\n",
    "lat_lex_uri = create_uri(LP, \"lexicon\", \"la\", namespace_sep)\n",
    "g.add((lat_lex_uri, RDF.type, LIME.lexicon))\n",
    "g.add((lat_lex_uri, RDFS.label, Literal('Latin lexicon')))\n",
    "g.add((lat_lex_uri, DCT.language, Literal('la')))\n",
    "\n",
    "eng_lex_uri = create_uri(LP, \"lexicon\", \"en\", namespace_sep)\n",
    "g.add((eng_lex_uri, RDF.type, LIME.lexicon))\n",
    "g.add((eng_lex_uri, RDFS.label, Literal('English lexicon')))\n",
    "g.add((eng_lex_uri, DCT.language, Literal('En')))\n",
    "\n",
    "# Create  triples for each expression\n",
    "for index, row in df_latin.iterrows():\n",
    "    \n",
    "    expr_id = row['id']\n",
    "    latin_expr = row['latin_expression']    \n",
    "    branch = row['branch']\n",
    "    branch_url = row['branch_url']\n",
    "    expr_url = row['expression_url']        \n",
    "    concept = row['concept']\n",
    "    expr_trans_eng = row['translation_eng']\n",
    "\n",
    "    print(latin_expr)\n",
    "    \n",
    "    # Lexical concept\n",
    "    concept_uri = create_uri(LP, \"concept\", index, namespace_sep)\n",
    "    g.add((concept_uri, RDF.type, ONTOLEX.LexicalConcept))\n",
    "    g.add((concept_uri, RDFS.label,  Literal(f'Lexical concept of {latin_expr}', lang=\"en\")))\n",
    "    g.add((concept_uri, SKOS.definition, Literal(concept, lang=\"en\"))) \n",
    "    sem_annot_uri = create_uri(LP, 'semantics', index, namespace_sep)\n",
    "    g.add((sem_annot_uri, RDFS.label, Literal(f'Semantic annotation of {latin_expr}')))\n",
    "    g.add((sem_annot_uri, RDF.type, POWLA.Node))\n",
    "    g.add((sem_annot_uri, POWLA.hasLayer, sem_layer))\n",
    "    g.add((sem_annot_uri, DC.subject, concept_uri))\n",
    "\n",
    "    if linked_concepts_dict.get(expr_id):\n",
    "        linked_concepts_dict[expr_id]['uri'] = concept_uri\n",
    "    \n",
    "    # Link to branch of philosophy\n",
    "    branch_id = branch.lower().replace(\" \", \"-\")\n",
    "    branch_uri = create_uri(LP, \"branch\", branch_id, namespace_sep)\n",
    "    g.add((branch_uri, RDF.type, SKOS.Concept))\n",
    "    g.add((branch_uri, SKOS.prefLabel, Literal(branch.capitalize(), lang=\"en\")))\n",
    "    g.add((concept_uri, SKOS.broader, branch_uri))   \n",
    "    if branch_url:   \n",
    "        g.add((branch_uri, RDFS.seeAlso, URIRef(branch_url)))\n",
    "        \n",
    "    # Link to Wikidata if available\n",
    "    wiki_id = expr_url.split('/')[-1] if expr_url else None    \n",
    "    if wiki_id:\n",
    "        g.add((concept_uri, RDFS.seeAlso, WD[wiki_id]))\n",
    "        \n",
    "    # Lexical entry for Latin expression\n",
    "    latin_entry_uri = create_uri(LP, \"expression\", index, namespace_sep, \"la\")\n",
    "    g.add((latin_entry_uri, RDF.type, ONTOLEX.LexicalEntry))\n",
    "    g.add((latin_entry_uri, RDFS.label, Literal(latin_expr, lang=\"la\")))    \n",
    "    g.add((latin_entry_uri, RDF.type, POWLA.root))\n",
    "    g.add((latin_entry_uri, ONTOLEX.evokes, concept_uri))\n",
    "    \n",
    "    # Lexical form\n",
    "    form_uri = create_uri(LP, \"form\", index, namespace_sep, \"la\")\n",
    "    g.add((form_uri, RDF.type, ONTOLEX.Form))\n",
    "    g.add((latin_entry_uri, ONTOLEX.canonicalForm, form_uri))\n",
    "    g.add((form_uri, ONTOLEX.writtenRep, Literal(latin_expr.capitalize(), lang=\"la\")))    \n",
    "   \n",
    "    # Lexical entry for English translation\n",
    "    english_entry_uri = create_uri(LP, \"expression\", index, namespace_sep, \"en\")\n",
    "    g.add((english_entry_uri, RDF.type, ONTOLEX.LexicalEntry))\n",
    "    g.add((english_entry_uri, RDFS.label, Literal(expr_trans_eng, lang=\"en\")))\n",
    "    g.add((english_entry_uri, ONTOLEX.evokes, concept_uri))\n",
    "    \n",
    "    # Canonical form for English\n",
    "    english_form_uri = create_uri(LP, \"form\", index, namespace_sep, \"en\")\n",
    "    g.add((english_form_uri, RDF.type, ONTOLEX.Form))\n",
    "    g.add((english_entry_uri, ONTOLEX.canonicalForm, english_form_uri))\n",
    "    g.add((english_form_uri, ONTOLEX.writtenRep, Literal(expr_trans_eng.capitalize(), lang=\"en\")))\n",
    "    \n",
    "    # Translation relation\n",
    "    trans_uri = create_uri(LP, \"translation\", index, namespace_sep)\n",
    "    g.add((trans_uri, RDF.type, VARTRANS.LexicalRel))\n",
    "    g.add((trans_uri, VARTRANS.category, Literal('philosophicalTranslation')))\n",
    "    g.add((trans_uri, RDFS.label, Literal(f'Translation of {latin_expr}')))\n",
    "    \n",
    "    g.add((trans_uri, VARTRANS.source, latin_entry_uri))\n",
    "    g.add((trans_uri, VARTRANS.target, english_entry_uri))\n",
    "\n",
    "    expr_index = f'expr-{index}'\n",
    "    \n",
    "    # Different interpretations\n",
    "    for sense_id , sense in df_senses[df_senses['id'] == expr_id].iterrows(): \n",
    "        \n",
    "        # Lexical sense\n",
    "        auth_id = sense['associated_with'].lower().replace(\" \", \"-\")\n",
    "        sense_uri = create_uri(LP, f'sense_{expr_index}', auth_id, namespace_sep)\n",
    "        g.add((sense_uri, RDF.type, ONTOLEX.LexicalSense))\n",
    "        g.add((latin_entry_uri, ONTOLEX.sense, sense_uri))   \n",
    "        g.add((sense_uri, RDFS.label, Literal(f'{sense['associated_with']} sense of {latin_expr}', lang=\"en\")))\n",
    "        g.add((sense_uri, SKOS.definition, Literal(sense['sense'], lang=\"en\")))\n",
    "        g.add((concept_uri, SKOS.narrower, sense_uri))\n",
    "\n",
    "        auth_uri = create_uri(LP, \"creator\", auth_id, namespace_sep)\n",
    "        g.add((auth_uri,  RDFS.label, Literal(sense['associated_with'], lang=\"en\")))\n",
    "        g.add((auth_uri, FOAF.page, URIRef(sense['associated_with_url'])))\n",
    "        g.add((sense_uri, DCT.creator, auth_uri))   \n",
    "        g.add((concept_uri, DCT.creator, auth_uri))\n",
    "        if sense['associated_with_url'] != '':   \n",
    "            g.add((auth_uri, RDFS.seeAlso, URIRef(sense['associated_with_url'])))       \n",
    "        \n",
    "        if auth_id == 'plato':\n",
    "            plato_uri = auth_uri\n",
    "            \n",
    "    # Add to citation layer\n",
    "    g.add((latin_entry_uri, POWLA.hasLayer, cit_uri))\n",
    "\n",
    "    # Add to lexicon layer\n",
    "    g.add((latin_entry_uri, LIME.entry, lat_lex_uri))\n",
    "    g.add((english_entry_uri, LIME.entry, eng_lex_uri))\n",
    "    \n",
    "    # Parse with UDPipe\n",
    "    conll = call_udpipe_and_parse(latin_expr.replace(\",\",\"\").replace(\"?\",\"\"))    \n",
    "    if conll:                              \n",
    "        for i, token in enumerate(conll[0]):\n",
    "                \n",
    "            # Terminal for the token\n",
    "            token_id = i + 1            \n",
    "            powla_token_uri = create_uri(LP, f'token{namespace_sep}{expr_index}', token_id, namespace_sep)\n",
    "            token_form = token.form\n",
    "                                                    \n",
    "            g.add((powla_token_uri, RDF.type, POWLA.Terminal))\n",
    "            g.add((powla_token_uri, RDFS.label, Literal(token_form, lang=\"la\")))\n",
    "            g.add((latin_entry_uri, POWLA.hasTerminal, powla_token_uri))\n",
    "            g.add((powla_token_uri, POWLA.hasLayer, doc_uri))\n",
    "    \n",
    "            # First, next, last token relations\n",
    "            if token_id == 1:\n",
    "                g.add((latin_entry_uri, POWLA.first, powla_token_uri))        \n",
    "            \n",
    "            if token_id == len(conll[0]):\n",
    "                g.add((latin_entry_uri, POWLA.last, powla_token_uri))\n",
    "    \n",
    "            if token_id > 1:\n",
    "                prev_token_uri = create_uri(LP, f'token{namespace_sep}{expr_index}', token_id - 1, namespace_sep)\n",
    "                g.add((powla_token_uri, POWLA.prev, prev_token_uri))\n",
    "                g.add((prev_token_uri, POWLA.next, powla_token_uri))\n",
    "    \n",
    "            # Dependency relation\n",
    "            if token.head:\n",
    "                token_head = int(token.head)\n",
    "                if token_head != 0:                   \n",
    "                    dep_relation_uri = create_uri(LP, f'deprel{namespace_sep}{expr_index}', f'{token_head}-{token_id}', namespace_sep)\n",
    "                    powla_head_uri = create_uri(LP, f'token{namespace_sep}{expr_index}', token_head, namespace_sep)                                        \n",
    "                    g.add((dep_relation_uri, RDF.type, POWLA.relation))\n",
    "                    ud_deprel = token.deprel.split(':')[0]\n",
    "                    deprel_uri = create_uri(LP, f'deprel', ud_deprel, namespace_sep)\n",
    "                    g.add((deprel_uri, RDF.type, URIRef(f'https://universaldependencies.org/u/dep/{ud_deprel}')))\n",
    "                    g.add((deprel_uri, RDFS.label, Literal(f'UD {ud_deprel}'))) \n",
    "                    g.add((dep_relation_uri, RDF.type, deprel_uri))                    \n",
    "                    g.add((dep_relation_uri, RDFS.label, Literal(f'deprel: {token.deprel}')))\n",
    "                    g.add((dep_relation_uri, POWLA.hasLayer, dep_layer))\n",
    "                    g.add((dep_relation_uri, POWLA.hasSource, powla_head_uri))\n",
    "                    g.add((dep_relation_uri, POWLA.hasTarget, powla_token_uri))\n",
    "                    g.add((dep_relation_uri, POWLA.hasLabel, Literal(token.deprel)))    \n",
    "            \n",
    "            \n",
    "            # UD annotations from conllu\n",
    "            ud_node_uri = create_uri(LP, f'ud{namespace_sep}{expr_index}', token_id, namespace_sep)\n",
    "            g.add((ud_node_uri, RDFS.label, Literal(f'UD annotation of {token_form}')))\n",
    "            g.add((ud_node_uri, RDF.type, OA.annotation))\n",
    "            g.add((ud_node_uri, POWLA.hasLayer, ud_layer))\n",
    "            g.add((ud_node_uri, OA.hasTarget, powla_token_uri))\n",
    "            \n",
    "            # POS from conllu\n",
    "            pos_node_uri = create_uri(LP, 'pos', f'{token.upos}', namespace_sep)\n",
    "            g.add((pos_node_uri, RDFS.label, Literal(f'POS={token.upos}')))\n",
    "            g.add((pos_node_uri, RDF.type, URIRef(f'https://universaldependencies.org/u/pos/{token.upos}')))\n",
    "            g.add((URIRef(f'https://universaldependencies.org/u/pos/{token.upos}'), RDFS.label, Literal(f'UD {token.upos}')))\n",
    "            g.add((ud_node_uri, OA.hasBody, pos_node_uri))\n",
    "    \n",
    "            # Feats from conllu\n",
    "            feats = dict(token.feats)\n",
    "            for feat in feats:\n",
    "                for f in feats[feat]:\n",
    "                    feat_node_uri= create_uri(LP, 'feat', f'{feat.capitalize()}_{f.capitalize()}', namespace_sep)\n",
    "                    g.add((feat_node_uri, RDFS.label, Literal(f'{feat.capitalize()}={f.capitalize()}')))\n",
    "                    g.add((feat_node_uri, RDF.type, URIRef(f'https://universaldependencies.org/u/feat/{feat.capitalize()}#{f.capitalize()}')))\n",
    "                    g.add((URIRef(f'https://universaldependencies.org/la/feat/{feat.capitalize()}#{f.capitalize()}'), RDFS.label, Literal(f'{feat.capitalize()}={f.capitalize()}')))\n",
    "                    g.add((ud_node_uri, OA.hasBody, feat_node_uri))\n",
    "    \n",
    "            if token.form == 'Plato': # ad hoc, can be generalized?\n",
    "                plato_token_uri = powla_token_uri                \n",
    "            \n",
    "            # Link to LiLa lemma\n",
    "            try :\n",
    "                for sent in lila_linking[row['id']]['sentences']:\n",
    "                    for lila_token in sent:\n",
    "                        if lila_token['token'] == token_form:\n",
    "                            if len(lila_token['linking']) > 0:\n",
    "                                lila_link_info = lila_token['linking'][0].split(\":\")\n",
    "                                lila_lemma_id = lila_link_info[1]                \n",
    "                                lila_lemma_uri = URIRef(f'http://lila-erc.eu/data/id/lemma/{lila_lemma_id}')  \n",
    "                                g.add((lila_lemma_uri, RDF.type, LILA.lemma))\n",
    "                                g.add((lila_lemma_uri, RDFS.label, Literal(lila_token['lemma'])))\n",
    "                                g.add((lila_lemma_uri, DC.title, Literal(lila_token['lemma'])))\n",
    "                                g.add((powla_token_uri, LILA.hasLemma, lila_lemma_uri))\n",
    "                            else:\n",
    "                                print(latin_expr + \" \"+ \" unmatched token in LiLa \" + token.form + \" \" + lila_token['token'])\n",
    "            except :\n",
    "                print(latin_expr + \" \"+ \" error linking \" + token.form)\n",
    "\n",
    "try:\n",
    "    g.add((plato_token_uri, RDFS.seeAlso, plato_uri))\n",
    "except:\n",
    "    print(\"Plato error\")\n",
    "\n",
    "# Add links between concepts\n",
    "for key, value in linked_concepts_dict.items():\n",
    "     concept_uri = value['uri']\n",
    "     for link in value['links']:\n",
    "         g.add((concept_uri, SKOS.related, linked_concepts_dict[link]['uri']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b62167-3321-496a-927c-1407c9d71bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(g.serialize(format=\"turtle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c32fe8-8f04-462b-b31d-c476ef298e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a582f18-dfc2-4e63-a8bc-a30185265301",
   "metadata": {},
   "source": [
    "### Serialize triplestore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9cd30eaf-d842-4c4e-94cd-95492d39737d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N1d9384cb73b24aaf8cb70c524b9ab0ae (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.serialize(format=\"turtle\", destination=\"Latin-Philosophical-Expression.ttl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2116db-de2a-4059-814e-4c658b5c0f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b3ab39-d45d-4bea-8b4b-09192aad2e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
