{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation for Linking Latin Philosophical Expressions project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "G8fRe5TFotvf"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.load.dump import dumps\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic.config import ConfigDict\n",
    "from typing import Annotated, Literal\n",
    "from enum import Enum\n",
    "from typing import Literal\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VjcJvneBnkZP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QEyXV8WTN98r"
   },
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    api_key= os.getenv(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_expression_id(expression):\n",
    "    expression = expression.lower().replace(\",\", \"\").replace(\"?\", \"\")\n",
    "    w = expression.split(\" \")\n",
    "    return \"_\".join(w[ : 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(base_prompt, parser):\n",
    "\n",
    "    template = base_prompt + \"\\n\" + \"{format_instructions}'\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template = template,\n",
    "        input_variables = [\"expression\"],\n",
    "        partial_variables = {\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expressions = []\n",
    "with open('./expressions.txt') as f:\n",
    "    expressions = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition, translation and branch of philosophy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDEMGOT7ny4p"
   },
   "outputs": [],
   "source": [
    "class PhiloExpression(BaseModel):\n",
    "    translation : str\n",
    "    explanation : str\n",
    "    branch : Literal['Epistemology', 'Metaphysics', 'Logic', 'Aesthetics' , 'Ethics', 'Political Philosophy','Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1aX-N1PZo7Np"
   },
   "outputs": [],
   "source": [
    "base_prompt = \"\"\"You are an academic professor of philosophy. I will submit to you a Latin expression with a specific meaning in philosophy.\n",
    "Please provide in output:\n",
    "\n",
    "1) the literal English translation\n",
    "2) a detailed explanation of its meaning in philosophy\n",
    "3) the brach of philosophy it belongs to\n",
    "\n",
    "This is the expression : {expression}\n",
    "\"\"\"\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object = PhiloExpression)\n",
    "prompt = get_prompt(base_prompt, parser)\n",
    "chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LIa3W675sBK4"
   },
   "outputs": [],
   "source": [
    "result_file = './Latin-Philosophical-Expressions-ChatGPT.csv'\n",
    "df = pd.DataFrame(columns = ['id', 'latin_expression','concept','branch','translation_eng'])\n",
    "df.to_csv(result_file, encoding = \"utf-8\", index = False)\n",
    "\n",
    "for expression in expressions:\n",
    "  print(expression)\n",
    "\n",
    "  try:\n",
    "    result = chain.invoke({\"expression\": expression})\n",
    "    new_row = {\n",
    "        'id' : generate_expression_id(expression),\n",
    "        'latin_expression': expression,\n",
    "        'concept': result.explanation,\n",
    "        'branch': result.branch,\n",
    "        'translation_eng': result.translation        \n",
    "    }\n",
    "    df = pd.DataFrame([new_row])\n",
    "    df.to_csv(result_file, encoding = \"utf-8\", mode='a', index=False, header=False)\n",
    "  except:\n",
    "    print(\"Error: \", expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5hD3AliepiU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksfeGg92sG2b"
   },
   "source": [
    "### Interpretations by philosophers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ULcLrsDi4EYp"
   },
   "outputs": [],
   "source": [
    "class PhiloExpressionSense(BaseModel):\n",
    "  associatedWith : str\n",
    "  interpretation : str\n",
    "\n",
    "class PhiloExpressionSenses(BaseModel):\n",
    "  interpretations : list[PhiloExpressionSense]\n",
    "\n",
    "base_concept_prompt = \"\"\"Given the following Latin philosophical expression: \"{expression}\",\n",
    "    provide a list of different interpretations of the expression given by different philosophers or philosophical schools.\n",
    "    The output should be a list of JSON objects where each element should have:\n",
    "    - \"associatedWith\": the philosopher connected to a specific interpretation\n",
    "    - \"interpretation\": a detailed explanation of that interpretation\n",
    "    Provide at least 2 and at most 5 different interpretations.\"\"\"\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object = PhiloExpressionSenses)\n",
    "prompt = get_prompt(base_concept_prompt, parser)\n",
    "chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rfWgnqs4d4s"
   },
   "outputs": [],
   "source": [
    "result_file = './Latin-Expressions-Interpretations-ChatGPT.csv'\n",
    "df = pd.DataFrame(columns = ['id', 'expression', 'associated_with', 'sense'])\n",
    "df.to_csv(result_file, encoding = \"utf-8\", index = False)\n",
    "\n",
    "for expression in expressions:\n",
    "  print(expression)\n",
    "\n",
    "  try:\n",
    "    result = chain.invoke({\"expression\": expression})\n",
    "    for sense in result.interpretations:\n",
    "        new_row = {\n",
    "            'id' : generate_expression_id(expression),\n",
    "            'expression': expression,\n",
    "            'associated_with' : sense.associatedWith,\n",
    "            'sense': sense.interpretation\n",
    "        }\n",
    "        df = pd.DataFrame([new_row])\n",
    "        df.to_csv(result_file, encoding = \"utf-8\", mode='a', index=False, header=False)\n",
    "  except:\n",
    "    print(\"Error: \", expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vfxl2URtsRjf",
    "outputId": "18247f85-1ead-40e1-c004-73cbfa815dde"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
